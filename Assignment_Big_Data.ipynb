{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ipin131/NLP-Myanimelist-Review-Singeky-no-kyojin/blob/main/Assignment_Big_Data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install selenium\n"
      ],
      "metadata": {
        "id": "L_FU2bKzCFXT",
        "outputId": "aba9363c-0d2d-483f-b8c9-7fc7def09567",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: selenium in /usr/local/lib/python3.10/dist-packages (4.27.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.26 in /usr/local/lib/python3.10/dist-packages (from urllib3[socks]<3,>=1.26->selenium) (2.2.3)\n",
            "Requirement already satisfied: trio~=0.17 in /usr/local/lib/python3.10/dist-packages (from selenium) (0.27.0)\n",
            "Requirement already satisfied: trio-websocket~=0.9 in /usr/local/lib/python3.10/dist-packages (from selenium) (0.11.1)\n",
            "Requirement already satisfied: certifi>=2021.10.8 in /usr/local/lib/python3.10/dist-packages (from selenium) (2024.8.30)\n",
            "Requirement already satisfied: typing_extensions~=4.9 in /usr/local/lib/python3.10/dist-packages (from selenium) (4.12.2)\n",
            "Requirement already satisfied: websocket-client~=1.8 in /usr/local/lib/python3.10/dist-packages (from selenium) (1.8.0)\n",
            "Requirement already satisfied: attrs>=23.2.0 in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium) (24.2.0)\n",
            "Requirement already satisfied: sortedcontainers in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium) (2.4.0)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium) (3.10)\n",
            "Requirement already satisfied: outcome in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium) (1.3.0.post0)\n",
            "Requirement already satisfied: sniffio>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium) (1.2.2)\n",
            "Requirement already satisfied: wsproto>=0.14 in /usr/local/lib/python3.10/dist-packages (from trio-websocket~=0.9->selenium) (1.2.0)\n",
            "Requirement already satisfied: pysocks!=1.5.7,<2.0,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from urllib3[socks]<3,>=1.26->selenium) (1.7.1)\n",
            "Requirement already satisfied: h11<1,>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.14.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Hanya untuk 1 halaman\n",
        "\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "\n",
        "# URL target\n",
        "url = \"https://myanimelist.net/anime/16498/Shingeki_no_Kyojin/reviews\"\n",
        "\n",
        "# Fungsi untuk scraping data ulasan\n",
        "def scrape_reviews(url):\n",
        "    response = requests.get(url)\n",
        "    soup = BeautifulSoup(response.content, 'html.parser')\n",
        "\n",
        "    reviews = []\n",
        "\n",
        "    # Cari setiap ulasan berdasarkan kategori\n",
        "    for review_section in soup.find_all('div', class_='review-element'):\n",
        "        try:\n",
        "            # Ambil kategori ulasan (Recommended, Mixed Feelings, Not Recommended)\n",
        "            category = review_section.find('div', class_='tag').get('data-id')\n",
        "            # Ambil teks ulasan\n",
        "            text = review_section.find('div', class_='text').get_text(strip=True)\n",
        "            reviews.append({'Category': category, 'Review': text})\n",
        "        except AttributeError:\n",
        "            continue\n",
        "\n",
        "    return reviews\n",
        "\n",
        "# Scrape dan simpan ke DataFrame\n",
        "data = scrape_reviews(url)\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Simpan ke CSV\n",
        "df.to_csv(\"reviews.csv\", index=False)\n",
        "print(\"Data berhasil disimpan ke 'reviews.csv'\")\n"
      ],
      "metadata": {
        "id": "G_QI32n6BN-B",
        "outputId": "6455e7bc-2b32-4289-d584-bc7a203e0408",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data berhasil disimpan ke 'reviews.csv'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 3 Halaman review\n",
        "\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "\n",
        "# Fungsi untuk scraping data ulasan dari satu halaman\n",
        "def scrape_reviews(url):\n",
        "    response = requests.get(url)\n",
        "    soup = BeautifulSoup(response.content, 'html.parser')\n",
        "\n",
        "    reviews = []\n",
        "\n",
        "    # Cari setiap ulasan berdasarkan kategori\n",
        "    for review_section in soup.find_all('div', class_='review-element'):\n",
        "        try:\n",
        "            # Ambil kategori ulasan (Recommended, Mixed Feelings, Not Recommended)\n",
        "            category = review_section.find('div', class_='tag').get('data-id')\n",
        "            # Ambil teks ulasan\n",
        "            text = review_section.find('div', class_='text').get_text(strip=True)\n",
        "            reviews.append({'Category': category, 'Review': text})\n",
        "        except AttributeError:\n",
        "            continue\n",
        "\n",
        "    return reviews\n",
        "\n",
        "# URL target untuk halaman 1, 2, dan 3\n",
        "urls = [\n",
        "    \"https://myanimelist.net/anime/16498/Shingeki_no_Kyojin/reviews?sort=suggested&filter_check=&filter_hide=&preliminary=on&spoiler=off&p=1\",\n",
        "    \"https://myanimelist.net/anime/16498/Shingeki_no_Kyojin/reviews?sort=suggested&filter_check=&filter_hide=&preliminary=on&spoiler=off&p=2\",\n",
        "    \"https://myanimelist.net/anime/16498/Shingeki_no_Kyojin/reviews?sort=suggested&filter_check=&filter_hide=&preliminary=on&spoiler=off&p=3\"\n",
        "]\n",
        "\n",
        "# Gabungkan semua ulasan dari halaman-halaman yang berbeda\n",
        "all_reviews = []\n",
        "for url in urls:\n",
        "    all_reviews.extend(scrape_reviews(url))\n",
        "\n",
        "# Simpan ke DataFrame\n",
        "df = pd.DataFrame(all_reviews)\n",
        "\n",
        "# Simpan ke CSV\n",
        "df.to_csv(\"reviews.csv\", index=False)\n",
        "print(\"Data berhasil disimpan ke 'reviews.csv'\")\n"
      ],
      "metadata": {
        "id": "HsyWGfduNCJi",
        "outputId": "c5403384-5291-472d-9482-5a898e293509",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data berhasil disimpan ke 'reviews.csv'\n"
          ]
        }
      ]
    },
    {
      "source": [
        "!pip install nltk\n",
        "import nltk\n",
        "nltk.download('punkt_tab')\n",
        "import re\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "# Preprocessing function\n",
        "def preprocess_text(text):\n",
        "    # Hapus simbol dan angka\n",
        "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
        "    # Lowercasing\n",
        "    text = text.lower()\n",
        "    # Tokenisasi\n",
        "    tokens = word_tokenize(text)\n",
        "    # Hapus stopwords\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    tokens = [word for word in tokens if word not in stop_words]\n",
        "    return ' '.join(tokens)\n",
        "\n",
        "# Terapkan preprocessing ke data\n",
        "df['Processed_Review'] = df['Review'].apply(preprocess_text)\n",
        "\n",
        "# Simpan hasil preprocessing\n",
        "df.to_csv(\"reviews_preprocessed.csv\", index=False)\n",
        "print(\"Data preprocessed berhasil disimpan ke 'reviews_preprocessed.csv'\")"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "3JMg1NtAG1aT",
        "outputId": "f43856a0-c81b-468c-a974-697afaee9794",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.9.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2024.9.11)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.6)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data preprocessed berhasil disimpan ke 'reviews_preprocessed.csv'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Load the dataset\n",
        "csv_path = \"reviews_preprocessed.csv\"\n",
        "df = pd.read_csv(csv_path)\n",
        "\n",
        "# Ensure the required columns exist\n",
        "if 'Processed_Review' in df.columns and 'Category' in df.columns:\n",
        "    # Step 2: Vektorisasi data ulasan\n",
        "    vectorizer = CountVectorizer()\n",
        "    X = vectorizer.fit_transform(df['Processed_Review'])\n",
        "    y = df['Category']\n",
        "\n",
        "    # Step 3: Split data into training and testing sets\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "    # Step 4: Train and evaluate Naive Bayes model\n",
        "    nb_model = MultinomialNB()\n",
        "    nb_model.fit(X_train, y_train)\n",
        "    nb_preds = nb_model.predict(X_test)\n",
        "\n",
        "    # Step 5: Train and evaluate SVM model\n",
        "    svm_model = SVC(kernel='linear')\n",
        "    svm_model.fit(X_train, y_train)\n",
        "    svm_preds = svm_model.predict(X_test)\n",
        "\n",
        "    # Step 6: Evaluation metrics\n",
        "    print(\"Naive Bayes Report:\")\n",
        "    print(classification_report(y_test, nb_preds))\n",
        "\n",
        "    print(\"SVM Report:\")\n",
        "    print(classification_report(y_test, svm_preds))\n",
        "else:\n",
        "    print(\"Required columns 'Processed_Review' and 'Category' are missing in the CSV.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cgaEpsbUHDnY",
        "outputId": "7dea4486-de70-4dbc-9bd6-808664e350d1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Naive Bayes Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.60      0.86      0.71         7\n",
            "           2       1.00      0.20      0.33         5\n",
            "           3       0.00      0.00      0.00         0\n",
            "\n",
            "    accuracy                           0.58        12\n",
            "   macro avg       0.53      0.35      0.35        12\n",
            "weighted avg       0.77      0.58      0.55        12\n",
            "\n",
            "SVM Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.67      0.86      0.75         7\n",
            "           2       0.67      0.40      0.50         5\n",
            "\n",
            "    accuracy                           0.67        12\n",
            "   macro avg       0.67      0.63      0.62        12\n",
            "weighted avg       0.67      0.67      0.65        12\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}